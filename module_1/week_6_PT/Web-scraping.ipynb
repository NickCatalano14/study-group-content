{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"verdana\" size=\"6\" color=\"blue\">Introducing Webscraping</font> ![](https://miro.medium.com/max/990/1*AaAIETIq7XNlLrFQW7BtZg.png)\n",
    "\n",
    "1. <font color=\"blue\" size=4>What is Web scraping?</font>\n",
    "    - Web scraping is a technique that allows you to extract data from websites and store it locally or in a database. It's also known as web harvesting, data scraping or data crawling. There is a lot of software out there that you can install and use to web scrape. Today, I'm going to introduce you to a super friendly and free python package called Beautiful Soup but Scrapy is another free package out there thats popular.\n",
    "    \n",
    "2. <font color=\"blue\" size=4>Why do we need to web scrape?</font>\n",
    "    - Why do we need to webscrape? Most websites only allow you to view data thru a web browser. They don't offer the functionality to save a copy of their data. Manually coping the data could take large amounts of time. Scraping software can automate the process and perform the task within a fraction of the time.\n",
    "    \n",
    "3. <font color=\"blue\" size=4>What are some common instances of webscraping?</font>\n",
    "    - **E-commerce Websites:** Web scrapers can collect the data specially related to the price of a specific product from various e-commerce websites for their comparison.\n",
    "    - **Content Aggregators:** Web scraping is used widely by content aggregators like news aggregators and job aggregators for providing updated data to their users.\n",
    "    - **Marketing and Sales Campaigns:** Web scrapers can be used to get the data like emails, phone number etc. for sales and marketing campaigns.\n",
    "    - **Data for Machine Learning Projects:** Retrieval of data for machine learning projects depends upon web scraping.\n",
    "    \n",
    "4. <font color=\"blue\" size=4>How do we scrape?</font>\n",
    "\n",
    "    What are the basic components of a web page? There are typically around 4 basic components of a web page.\n",
    "\n",
    "    - html - which contains the main content of a page\n",
    "    - css - adds styling to make the page pretty\n",
    "    - js - javascript files add interactivity to pages\n",
    "    - JPG & PNG - are image formats used to show pictures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"verdana\" size=\"6\" color=\"blue\">HTML</font>\n",
    "\n",
    "Hypertext Markup Language is the expression of webpages. \n",
    "Its unlike python however in that it has no ability to rationalize. It can make text italicized or bold; it can create paragraphs; it cannot perform recursion. \n",
    "\n",
    "```html\n",
    "<!DOCTYPE html>  \n",
    "<html>  \n",
    "    <!-- This is the syntax for adding helpful comments that will not be rendered to the browser -->\n",
    "    <head>   \n",
    "        \n",
    "    </head>\n",
    "    \n",
    "    <body>\n",
    "        <!-- The following are html elements. There is a good resource for html documentation at the end of this notebook --> \n",
    "\n",
    "        <h1>My Heading</h1>\n",
    "        <p>My Paragraph</p>\n",
    "        \n",
    "    </body>\n",
    "\n",
    "</html>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To extract data using web scraping with python, you need to follow these basic steps:**\n",
    "\n",
    "1. <font color=\"blue\">Find the URL that you want to scrape</font>\n",
    "2. <font color=\"blue\">Inspect the Page</font>\n",
    "3. <font color=\"blue\">Find the data you want to extract</font>\n",
    "4. <font color=\"blue\">Build a simple scraper</font>\n",
    "5. <font color=\"blue\">Modify the scraper to get rid of html and extract all the useful data</font>\n",
    "6. <font color=\"blue\">Store the data in the required format</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T19:29:10.562271Z",
     "start_time": "2020-06-30T19:29:09.625711Z"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests \n",
    "import re  \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T17:40:45.188681Z",
     "start_time": "2020-06-30T17:40:44.893152Z"
    }
   },
   "source": [
    "<font face=\"verdana\" size=\"4\" color=\"blue\">Let's scrape some quotes from this website - http://quotes.toscrape.com/</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T18:41:41.931816Z",
     "start_time": "2020-06-30T18:41:41.929828Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”\n",
      "“It is our choices, Harry, that show what we truly are, far more than our abilities.”\n",
      "“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”\n",
      "“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”\n",
      "“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\n",
      "“Try not to become a man of success. Rather become a man of value.”\n",
      "“It is better to be hated for what you are than to be loved for what you are not.”\n",
      "“I have not failed. I've just found 10,000 ways that won't work.”\n",
      "“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\n",
      "“A day without sunshine is like, you know, night.”\n"
     ]
    }
   ],
   "source": [
    "#build a simple soup\n",
    "url = 'http://quotes.toscrape.com/'\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "quotes = soup.find_all('span', class_= 'text')\n",
    "\n",
    "for quote in quotes:\n",
    "    print(quote.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"verdana\" size=\"4\" color=\"blue\">Activity - Break off into groups and get the Authors</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-30T19:29:13.924406Z",
     "start_time": "2020-06-30T19:29:13.293199Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ResultSet object has no attribute 'text'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-d1515d7b0842>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'tag'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/bs4/element.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2079\u001b[0m         \u001b[0;34m\"\"\"Raise a helpful exception to explain a common code fix.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2080\u001b[0m         raise AttributeError(\n\u001b[0;32m-> 2081\u001b[0;31m             \u001b[0;34m\"ResultSet object has no attribute '%s'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2082\u001b[0m         )\n",
      "\u001b[0;31mAttributeError\u001b[0m: ResultSet object has no attribute 'text'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?"
     ]
    }
   ],
   "source": [
    "tags = soup.find_all('div', class_= 'tags')\n",
    "\n",
    "for tag in tags:\n",
    "    \n",
    "    tag = tag.find_all('a', class_ = 'tag')\n",
    "    \n",
    "    print(tag.text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Albert Einstein\n",
      "“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”\n",
      "change\n",
      "deep-thoughts\n",
      "thinking\n",
      "world\n",
      "J.K. Rowling\n",
      "“It is our choices, Harry, that show what we truly are, far more than our abilities.”\n",
      "abilities\n",
      "choices\n",
      "Albert Einstein\n",
      "“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”\n",
      "inspirational\n",
      "life\n",
      "live\n",
      "miracle\n",
      "miracles\n",
      "Jane Austen\n",
      "“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”\n",
      "aliteracy\n",
      "books\n",
      "classic\n",
      "humor\n",
      "Marilyn Monroe\n",
      "“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\n",
      "be-yourself\n",
      "inspirational\n",
      "Albert Einstein\n",
      "“Try not to become a man of success. Rather become a man of value.”\n",
      "adulthood\n",
      "success\n",
      "value\n",
      "André Gide\n",
      "“It is better to be hated for what you are than to be loved for what you are not.”\n",
      "life\n",
      "love\n",
      "Thomas A. Edison\n",
      "“I have not failed. I've just found 10,000 ways that won't work.”\n",
      "edison\n",
      "failure\n",
      "inspirational\n",
      "paraphrased\n",
      "Eleanor Roosevelt\n",
      "“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\n",
      "misattributed-eleanor-roosevelt\n",
      "Steve Martin\n",
      "“A day without sunshine is like, you know, night.”\n",
      "humor\n",
      "obvious\n",
      "simile\n"
     ]
    }
   ],
   "source": [
    "authors = soup.find_all('small', class_= 'author')\n",
    "tags = soup.find_all('div', class_= 'tags')\n",
    "\n",
    "for i in range(0,len(quotes)):\n",
    "    print(authors[i].text)\n",
    "    print(quotes[i].text)\n",
    "    quoteTags = tags[i].find_all('a', class_ = 'tag')\n",
    "    \n",
    "    for quoteTag in quoteTags:\n",
    "        print(quoteTag.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
